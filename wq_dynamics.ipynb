{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014459d6",
   "metadata": {},
   "source": [
    "# Investigating water quality dynamics in adaptive distribution networks with dynamic topology and control\n",
    "\n",
    "Prepared by: Bradley Jenks\\\n",
    "Last updated: July 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6ca85",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "This notebook investigates the impact of hydraulic control on temporal disinfectant variability in a large-scale operational network. This is performed through the following tasks:\n",
    "1) Present case study network data and hydraulic control scenarios\n",
    "2) Compute flow variability metrics to visualise hydraulic dynamics\n",
    "3) Simulate disinfectant residuals under the considered control scenarios\n",
    "4) Validate impacts of dynamic connectivity and hydraulic control through sensor data\n",
    "\n",
    "The main outcome of this study is to evaluate if the considered hydraulic controls lead to increased disinfectant variability through changes in source water and possibly increased water quality dynamics. The flow variability metrics aim to inform areas in the network which stand to benefit from increased observability through sensor installations and/or manual grab sampling. Furthermore, insights from this study motivate the need for increased controllability of water quality dynamics in adaptive networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00cfa64",
   "metadata": {},
   "source": [
    "### Bristol Water Field Lab\n",
    "#### Network description\n",
    "The Bristol Water Field Lab network (BWFLnet) is a unique smart water demonstrator jointly operated by Imperial College London, Bristol Water Plc, and Cla-Val Ltd. It comprises two adjacent district metered areas (DMAs), which have been hydraulically connected via dynamic boundary valves. The network layout and properties are illustrated below using the `wntr` package, which is a Python wrapper for the open-source EPANET modelling software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from itertools import combinations\n",
    "\n",
    "import wntr\n",
    "\n",
    "net_name = 'bwfl_2022_05_hw.inp'\n",
    "project_dir = os.getcwd()\n",
    "data_path = os.path.join(project_dir, 'data/')\n",
    "\n",
    "wdn = load_network_data(os.path.join(data_path, net_name))\n",
    "\n",
    "# improve matplotlib image quality\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg') # remove when saving plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392ddcd",
   "metadata": {},
   "source": [
    "Print network properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe66890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of nodes = {wdn.net_info['nn']}\")\n",
    "print(f\"Number of links = {wdn.net_info['np']}\")\n",
    "print(f\"Number of sources = {wdn.net_info['n0']}\")\n",
    "print(f\"Number of 15-minute time steps = {wdn.net_info['nt']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182307c",
   "metadata": {},
   "source": [
    "BWFLnet has conitinuous MetriNet water quality sensors installed at nine (9) locations across the network. These locations are highlighted in the network layout plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor node data\n",
    "sensor_names = ['node_2746', 'node_1811', 'node_2367', 'node_2747', 'node_1809', 'node_2673', 'node_2506', 'node_1773', 'node_1802']\n",
    "\n",
    "# plot network layout\n",
    "legend_labels = {'Inlet (source)': 'black', 'Sensor node': 'black'}\n",
    "plot_network_layout(wdn, sensor_nodes=sensor_names, legend_labels=legend_labels, sensor_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbd48b",
   "metadata": {},
   "source": [
    "#### Control configurations\n",
    "In this study, we consider three (3) hydraulic control configurations for investigating water quality dynamics. These configurations employ the following valve types: (i) pressure reducing valves (PRVs); (ii) dynamic boundary valves (DBVs); and automatic flushing valves (AFVs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7078d29",
   "metadata": {},
   "source": [
    "1. **Single-feed DMAs.** This scenario considers a fixed topology with kept-shut isolation valves (IVs) separating the two DMAs. Furthermore, there is fixed-outlet pressure control at the DMA inlets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no control valves\n",
    "prv = ['link_2756', 'link_2729', 'link_2743']\n",
    "dbv = ['link_2747', 'link_2748']\n",
    "iv_open = ['link_2320']\n",
    "iv_close = ['link_2236', 'link_2682', 'link_2431', 'link_2389', 'link_2508', 'link_2555']\n",
    "\n",
    "# find connecting nodes\n",
    "prv_nodes = []\n",
    "for link_id in prv:\n",
    "    prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "    \n",
    "dbv_nodes = []\n",
    "for link_id in dbv:\n",
    "    dbv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "    \n",
    "iv_close_nodes = []\n",
    "for link_id in iv_close:\n",
    "    iv_close_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "# plot network layout\n",
    "legend_labels = {'Inlet (source)': 'black', 'IV': 'black'}\n",
    "plot_network_layout(wdn, prv_nodes=prv_nodes, iv_nodes=iv_close_nodes+dbv_nodes, legend_labels=legend_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500acfd",
   "metadata": {},
   "source": [
    "2. **Average zone pressure control.** This configuration represents the existing controls in BWFLnet, as operated by Bristol Water. PRVs are in the same locations as the single-feed DMA configuration, but they now have dynamic set-points at each 15-minute control interval. Additionally, two of the kept-shut IVs are replaced with remote-controlled throttle control valves, referred to as dynamic boundary valves (DBVs). These are programmed to shut during the overnight period for leakage management purposes and open during the day to convey flow between DMAs. The following paper describes this control configuration in more detail.\n",
    "    * Wright, R., Stoianov, I., Parpas, P., Henderson, K., and King, J. (2015). 'Adaptive water distribution networks with dynamically reconfigurable topology.' Journal of Hydroinformatics 16(6), 1280–1301, doi: 10.2166/hydro.2014.086."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bafb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# existing control valves\n",
    "prv = ['link_2756', 'link_2729', 'link_2743']\n",
    "prv_dir = [1, 1, 1]\n",
    "dbv = ['link_2747', 'link_2748']\n",
    "iv_open = ['link_2320']\n",
    "iv_close = ['link_2236', 'link_2682', 'link_2431', 'link_2389', 'link_2508', 'link_2555']\n",
    "\n",
    "# find connecting nodes\n",
    "prv_nodes = []\n",
    "for link_id in prv:\n",
    "    prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "    \n",
    "dbv_nodes = []\n",
    "for link_id in dbv:\n",
    "    dbv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "    \n",
    "iv_close_nodes = []\n",
    "for link_id in iv_close:\n",
    "    iv_close_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "# plot network layout\n",
    "legend_labels = {'Inlet (source)': 'black', 'PRV': 'black', 'DBV': 'black', 'IV': 'black'}\n",
    "plot_network_layout(wdn, prv_nodes=prv_nodes, dbv_nodes=dbv_nodes, iv_nodes=iv_close_nodes, legend_labels=legend_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3eb339",
   "metadata": {},
   "source": [
    "**Self-cleaning control.** This self-cleaning configuration considers a new design strategy for managing discolouration and pressure management objectives. The design comprises PRVs at new locations and with dynamic set-points at 15-minute intervals. Additionally, automatic flushing valves (AFVs) are installed with dynamic flushing rates at the same frequency. The locations of PRV and AFV locations were optimized using the methods proposed in the following paper:\n",
    "   * Jenks, B., Ulusoy, A.-J., Pecci, F., and Stoianov, I. (2023). 'Dynamically adaptive networks for integrating optimal pressure management and self-cleaning controls.' Annual Reviews in Control 55, pp. 486–497, doi: 10.1016/j.arcontrol.2023.03.014       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96cd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-cleaning control valves\n",
    "prv_new = ['link_1963', 'link_0749', 'link_0615']\n",
    "prv_new_dir = [-1, -1, 1]\n",
    "iv_open = ['link_2320']\n",
    "iv_close = ['link_2236', 'link_2682', 'link_2431', 'link_2389', 'link_2508', 'link_2555']\n",
    "afv_nodes = ['node_1285', 'node_1236', 'node_2444', 'node_2095']\n",
    "\n",
    "# find connecting nodes\n",
    "prv_nodes = []\n",
    "for link_id in prv_new:\n",
    "    prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "# plot network layout\n",
    "legend_labels = {'Inlet (source)': 'black', 'PRV': 'black', 'AFV': 'black'}\n",
    "plot_network_layout(wdn, prv_nodes=prv_nodes, afv_nodes=afv_nodes, legend_labels=legend_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b7e5",
   "metadata": {},
   "source": [
    "### Flow variability metrics\n",
    "Here, we compute flow variability metrics corresponding to the selected control configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'self-cleaning control' # 'no control', existing control', 'self-cleaning control'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7ee2e",
   "metadata": {},
   "source": [
    "#### Hydraulic simulation\n",
    "We first update hydraulic controls based on the selected control scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_days_hyd = 1 # number of days in simulation\n",
    "\n",
    "# call 'set_controls' function\n",
    "if scenario == 'no control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close+dbv, iv_open=iv_open, sim_days=sim_days_hyd)\n",
    "        \n",
    "elif scenario == 'existing control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close, prv=prv, iv_open=iv_open, prv_dir=prv_dir, dbv=dbv, sim_days=sim_days_hyd)\n",
    "    \n",
    "elif scenario == 'self-cleaning control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_open=iv_close+iv_open, prv=prv_new, prv_dir=prv_new_dir, afv=afv_nodes, sim_days=sim_days_hyd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b6a29",
   "metadata": {},
   "source": [
    "The EPANET solver is then called via `wntr` to compute hydraulic states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91336976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24-hour simulation period with 15-minute time steps\n",
    "nt = 24\n",
    "wn.options.time.duration = (nt * sim_days_hyd * 3600) - (0.25 * 3600)\n",
    "wn.options.time.hydraulic_timestep = 60 * 15\n",
    "wn.options.time.report_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.options.time.rule_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.convert_controls_to_rules(priority=3) \n",
    "\n",
    "# run hydraulic solver\n",
    "sim = wntr.sim.EpanetSimulator(wn)\n",
    "results = sim.run_sim()\n",
    "\n",
    "# obtain flow at links\n",
    "df_flow = pd.DataFrame()\n",
    "df_flow['timestamp'] = results.link['flowrate'].index.values / 3600\n",
    "for col in results.link['flowrate'].columns:\n",
    "    df_flow[col] = results.link['flowrate'][col].values * 1000\n",
    "df_flow.set_index('timestamp', inplace=True)\n",
    "\n",
    "# obtain velocity at links\n",
    "df_vel = pd.DataFrame()\n",
    "df_vel['timestamp'] = results.link['velocity'].index.values / 3600\n",
    "for col in results.link['velocity'].columns:\n",
    "    df_vel[col] = results.link['velocity'][col].values\n",
    "df_vel.set_index('timestamp', inplace=True)\n",
    "\n",
    "\n",
    "# obtain pressure at nodes\n",
    "df_pressure = pd.DataFrame()\n",
    "df_pressure['timestamp'] = results.node['pressure'].index.values / 3600\n",
    "for col in results.node['pressure'].columns:\n",
    "    df_pressure[col] = results.node['pressure'][col].values\n",
    "df_pressure.set_index('timestamp', inplace=True)\n",
    "\n",
    "# obtain head at nodes\n",
    "df_head = pd.DataFrame()\n",
    "df_head['timestamp'] = results.node['head'].index.values / 3600\n",
    "for col in results.node['head'].columns:\n",
    "    df_head[col] = results.node['head'][col].values\n",
    "df_head.set_index('timestamp', inplace=True)\n",
    "\n",
    "# obtain demand at nodes\n",
    "df_demand = pd.DataFrame()\n",
    "df_demand['timestamp'] = results.node['demand'].index.values / 3600\n",
    "for col in results.node['demand'].columns:\n",
    "    df_demand[col] = results.node['demand'][col].values * 1000\n",
    "df_demand.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba406951",
   "metadata": {},
   "source": [
    "Let's first plot key hydraulic states to ensure the controls are functioning properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1fda2a",
   "metadata": {},
   "source": [
    "Hydraulic states across network, including hydraulic head, pressure head, flow rate, flow velocity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdbe23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting time step\n",
    "t = 38\n",
    "\n",
    "# network state to plot\n",
    "state = 'hydraulic head' # 'velocity', 'flow', 'pressure head', 'hydraulic head'\n",
    "vals_df = df_head.T\n",
    "\n",
    "# for AZP-SCC control configuration\n",
    "if scenario == \"self-cleaning control\":\n",
    "\n",
    "    # prvs for SCC objective\n",
    "    prv_nodes = []\n",
    "    for link_id in prv_new:\n",
    "        prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "    \n",
    "    legend_labels = {'Inlet': 'black', 'PRV': 'black', 'AFV': 'black'}\n",
    "    plot_network_states(wdn, plot_type=state, prv_nodes=prv_nodes, afv_nodes=afv_nodes, vals_df=vals_df, t=t, legend_labels=legend_labels)\n",
    "\n",
    "\n",
    "# for existing control configuration\n",
    "elif scenario == \"existing control\":\n",
    "\n",
    "    prv_nodes = []\n",
    "    for link_id in prv:\n",
    "        prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "        \n",
    "    dbv_nodes = []\n",
    "    for link_id in dbv:\n",
    "        dbv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "        \n",
    "    iv_close_nodes = []\n",
    "    for link_id in iv_close:\n",
    "        iv_close_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "    legend_labels = {'Inlet': 'black', 'PRV': 'black', 'DBV': 'black', 'IV': 'black'}\n",
    "    plot_network_states(wdn, plot_type=state, prv_nodes=prv_nodes, dbv_nodes=dbv_nodes, iv_nodes=iv_close_nodes, vals_df=vals_df, t=t, legend_labels=legend_labels)\n",
    "\n",
    "# for no control configuration\n",
    "elif scenario == \"no control\":\n",
    "\n",
    "    # prvs for no control\n",
    "    prv_nodes = []\n",
    "    for link_id in prv:\n",
    "        prv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "    dbv_nodes = []\n",
    "    for link_id in dbv:\n",
    "        dbv_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "\n",
    "    iv_close_nodes = []\n",
    "    for link_id in iv_close:\n",
    "        iv_close_nodes.extend(wdn.link_df.loc[wdn.link_df['link_ID'] == link_id, ['node_out', 'node_in']].values.flatten())\n",
    "        \n",
    "    legend_labels = {'Inlet': 'black', 'PRV': 'black', 'IV': 'black'}\n",
    "    plot_network_states(wdn, plot_type=state, prv_nodes=prv_nodes, iv_nodes=iv_close_nodes+dbv_nodes, vals_df=vals_df, t=t, legend_labels=legend_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc16b8",
   "metadata": {},
   "source": [
    "Pressure heads at inlet/outlet of pressure control valves (e.g. PRVs and DBVs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting data\n",
    "inlet = []\n",
    "outlet = []\n",
    "\n",
    "if scenario == 'existing control' or scenario == 'no control':\n",
    "    for idx, link in enumerate(prv):\n",
    "        if prv_dir[idx] == 1:\n",
    "            outlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_in']].to_numpy()[0][0])\n",
    "            inlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_out']].to_numpy()[0][0])\n",
    "        else:\n",
    "            inlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_in']].to_numpy()[0][0])\n",
    "            outlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_out']].to_numpy()[0][0])\n",
    "        \n",
    "elif scenario == 'self-cleaning control':\n",
    "    for idx, link in enumerate(prv_new):\n",
    "        if prv_new_dir[idx] == 1:\n",
    "            outlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_in']].to_numpy()[0][0])\n",
    "            inlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_out']].to_numpy()[0][0])\n",
    "        else:\n",
    "            inlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_in']].to_numpy()[0][0])\n",
    "            outlet.append(wdn.link_df.loc[wdn.link_df['link_ID'] == link, ['node_out']].to_numpy()[0][0])\n",
    "        \n",
    "# plotting code\n",
    "plt.figure(figsize=(5, 3.75))\n",
    "df_pressure[outlet].plot(label=outlet, figsize=(5, 3.75))\n",
    "# df_pressure[inlet].plot(label=inlet)\n",
    "plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "plt.ylabel('PRV setpoint [m]', fontsize=12)\n",
    "plt.tick_params(axis='x', labelsize=11)\n",
    "plt.tick_params(axis='y', labelsize=11)\n",
    "leg = plt.legend(loc='upper right', frameon=True, borderpad=0.5, fontsize=11)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(0.5)\n",
    "if sim_days_hyd <= 1:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 6))\n",
    "elif sim_days_hyd > 1 and sim_days_hyd < 5:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 12))\n",
    "else:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 24))\n",
    "\n",
    "# plt.ylim(12-1, 32+1)\n",
    "# plt.yticks((12, 16, 20, 24, 28, 32))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106d8d0",
   "metadata": {},
   "source": [
    "Time-based DBV loss coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario == 'existing control':\n",
    "\n",
    "    # plotting data\n",
    "    dbv_setting = pd.read_csv(os.path.join(data_path, 'dbv_exist_settings.csv')).T\n",
    "    dbv_setting.columns = dbv\n",
    "    dbv_setting = dbv_setting.div(1000000)\n",
    "\n",
    "    # plotting code\n",
    "    dbv_setting.plot(figsize=(5, 3.75))\n",
    "    plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "    plt.ylabel('Valve loss coefficient (x $10^6$)', fontsize=12)\n",
    "    plt.tick_params(axis='x', labelsize=11)\n",
    "    plt.tick_params(axis='y', labelsize=11)\n",
    "    leg = plt.legend(loc='upper right', frameon=True, borderpad=0.5, fontsize=11)\n",
    "    leg.get_frame().set_edgecolor('black')\n",
    "    leg.get_frame().set_linewidth(0.5)\n",
    "    plt.xticks(np.arange(0, len(dbv_setting)+1, len(dbv_setting) / 4), labels=np.arange(0, 25, 6))\n",
    "    plt.yticks((0, 5, 10, 15, 20))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f'DBVs or kept-shut IVs not included in \"{scenario}\" scenario.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74128eb7",
   "metadata": {},
   "source": [
    "Flow across boundary valves (e.g. DBVs and kept-shut BVs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario != 'self-cleaning control':\n",
    "    \n",
    "    # input plotting data\n",
    "    link_to_plot = dbv\n",
    "\n",
    "    # plotting code\n",
    "    df_flow[link_to_plot].plot(label=link_to_plot, figsize=(5, 3.75))\n",
    "    plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "    plt.ylabel('Flow [L/s]', fontsize=12)\n",
    "    if sim_days_hyd <= 1:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 6))\n",
    "    elif sim_days_hyd > 1 and sim_days_hyd < 5:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 12))\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 24))\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f'DBVs or kept-shut IVs not included in \"{scenario}\" scenario.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf56a5",
   "metadata": {},
   "source": [
    "Flushing demands at AFV nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if scenario == 'self-cleaning control':\n",
    "    \n",
    "    # input plotting data\n",
    "    node_to_plot = afv_nodes\n",
    "\n",
    "    # plotting code\n",
    "    df_demand[node_to_plot].plot(label=node_to_plot, figsize=(5, 3.75))\n",
    "    plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "    plt.ylabel('Flushing demand [L/s]', fontsize=12)\n",
    "    plt.tick_params(axis='x', labelsize=11)\n",
    "    plt.tick_params(axis='y', labelsize=11)\n",
    "    leg = plt.legend(loc='upper right', frameon=True, borderpad=0.5, fontsize=11)\n",
    "    leg.get_frame().set_edgecolor('black')\n",
    "    leg.get_frame().set_linewidth(0.5)\n",
    "    if sim_days_hyd <= 1:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 6))\n",
    "    elif sim_days_hyd > 1 and sim_days_hyd < 5:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 12))\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, nt * sim_days_hyd + 1, 24))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f'AFVs not included in \"{scenario}\" scenario.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6a94ca",
   "metadata": {},
   "source": [
    "#### Source trace simulation\n",
    "Another flow variability metric we consider is the contribution of source water at nodes across the network. This requires a water quality simulator.\n",
    "\n",
    "The control settings are updated to extend over a number of simulation days, thereby ensuring water reaches all nodes and periodic behaviour of hydraulic conditions is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_days_qual = 7 # number of days in simulation\n",
    "\n",
    "# call 'set_controls' function\n",
    "if scenario == 'no control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close+dbv, sim_days=sim_days_qual)\n",
    "        \n",
    "elif scenario == 'existing control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close, prv=prv, prv_dir=prv_dir, dbv=dbv, sim_days=sim_days_qual)\n",
    "    \n",
    "elif scenario == 'self-cleaning control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_open=iv_close+iv_open, prv=prv_new, prv_dir=prv_new_dir, afv=afv_nodes, sim_days=sim_days_qual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2fb472",
   "metadata": {},
   "source": [
    "The EPANET solver is called via `wntr` to compute water quality (source trace) states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25347376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24-hour simulation period with 15-minute time steps\n",
    "nt = 24\n",
    "wn.options.time.duration = (nt * sim_days_qual * 3600) - (0.25 * 3600)\n",
    "wn.options.time.hydraulic_timestep = 60 * 15\n",
    "wn.options.time.quality_timestep = 60 * 5\n",
    "wn.options.time.report_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.options.time.rule_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.convert_controls_to_rules(priority=3) \n",
    "\n",
    "# set trace parameters\n",
    "wn.options.quality.parameter = 'TRACE'\n",
    "sources = wdn.net_info['reservoir_names']\n",
    "df_trace_0 = pd.DataFrame()\n",
    "df_trace_1 = pd.DataFrame()\n",
    "\n",
    "# run water quality solver\n",
    "for idx, name in enumerate(sources):\n",
    "\n",
    "    # set trace node\n",
    "    wn.options.quality.trace_node = name\n",
    "    sim = wntr.sim.EpanetSimulator(wn)\n",
    "    results = sim.run_sim()\n",
    "    \n",
    "    # obtain quality at nodes\n",
    "    if idx == 0:\n",
    "        df_trace_0['timestamp'] = results.node['quality'].index.values / 3600\n",
    "        for col in results.node['quality'].columns:\n",
    "            df_trace_0[col] = results.node['quality'][col].values\n",
    "        df_trace_0.set_index('timestamp', inplace=True)\n",
    "    elif idx == 1:\n",
    "        df_trace_1['timestamp'] = results.node['quality'].index.values / 3600\n",
    "        for col in results.node['quality'].columns:\n",
    "            df_trace_1[col] = results.node['quality'][col].values\n",
    "        df_trace_1.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7b48d",
   "metadata": {},
   "source": [
    "Since '(existing) AZP control' and 'self-cleaning control' configurations allow flow transfer between DMAs, there are a number of nodes which may be supplied from both sources over the simulation period. In this work, we consider such conditions as increased **hydraulic dynamics** in the network. To highlight such areas, we take the maximum average source contribution over the simulation period, whereby nodes with lower values indicate greater **hydraulic dynamics**. Note that the average source contribution is computed across the last day in the simulation to ensure periodic behaviour is observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde960a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute maximum average source trace over last 24 hours in simulation period\n",
    "max_avg_trace = pd.concat([df_trace_0.tail(96).mean(), df_trace_1.tail(96).mean()], axis=1).max(axis=1)\n",
    "df_trace = pd.DataFrame(max_avg_trace, columns=['source_trace']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e81814",
   "metadata": {},
   "source": [
    "We confirm that periodic behaviour in water quality (source trace) states is observed by plotting select nodes most distant from each source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input plotting data\n",
    "# node_to_plot = 'node_1827' # north DMA node\n",
    "# node_to_plot = 'node_0447' # south DMA node\n",
    "# node_to_plot = 'node_0513' # node at DMA boundary\n",
    "node_to_plot = 'node_1152' # node at DMA boundary\n",
    "\n",
    "# plotting code\n",
    "plt.figure()\n",
    "df_trace_0[node_to_plot].plot(label=sources[0]+' trace', color='tab:blue')\n",
    "df_trace_1[node_to_plot].plot(label=sources[1]+' trace', color='tab:red')\n",
    "plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "plt.ylabel('Source trace [%]', fontsize=12)\n",
    "if sim_days_qual <= 1:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 6))\n",
    "elif sim_days_qual > 1 and sim_days_qual < 5:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 12))\n",
    "else:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 24))\n",
    "plt.legend(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1877bf",
   "metadata": {},
   "source": [
    "#### Flow variability metric plots\n",
    "We compute three (3) flow variability metrics to investigate hydraulic dynamics resulting from the considered control scenarios:\n",
    "* **Flow reversals**: the number of flow direction changes across a link during a 24-h simulation\n",
    "* **Flow coefficient of variation (CV)**: the relative variability of link flow across a 24-h simulation\n",
    "* **Mean source trace**: mean source trace percentage across the last 24-h period in a 7-day simulation\n",
    "\n",
    "These metrics are plotted below for the previously defined control scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87169519",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_metric = 'source trace' # 'flow reversal', 'vel cv', 'source trace'\n",
    "plot_temporal_metric(wdn, temporal_metric, df_flow, df_trace, sensor_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af95ea0",
   "metadata": {},
   "source": [
    "### Simulating disinfectant residuals\n",
    "Here, we simulate disinfectant residuals across BWFLnet for the selected control scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 'no control' # 'no control', existing control', 'self-cleaning control'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50ad9f",
   "metadata": {},
   "source": [
    "The control settings are again applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6adbf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_days_qual = 7 # number of days in simulation\n",
    "\n",
    "# call 'set_controls' function\n",
    "if scenario == 'no control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close+dbv, iv_open=iv_open, sim_days=sim_days_qual)\n",
    "        \n",
    "elif scenario == 'existing control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_close=iv_close, iv_open=iv_open, prv=prv, prv_dir=prv_dir, dbv=dbv, sim_days=sim_days_qual)\n",
    "    \n",
    "elif scenario == 'self-cleaning control':\n",
    "    wn = set_controls(net_name, data_path, scenario, iv_open=iv_open+iv_close, prv=prv_new, prv_dir=prv_new_dir, afv=afv_nodes, sim_days=sim_days_qual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872896a",
   "metadata": {},
   "source": [
    "Water quality simulation parameters are setup in the following code. Note that we apply disinfectant source patterns using sensor data observed at DMA inlets. We also apply bulk and pipe wall decay rates corresponding to recent modelling work in the Field Lab, the results of which are copied into the `get_wall_coeff` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42399b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set disinfectant source patterns\n",
    "\n",
    "# assign source locations\n",
    "source_0 = wdn.net_info['reservoir_names'][0]\n",
    "source_1 = wdn.net_info['reservoir_names'][1]\n",
    "\n",
    "# assign source values\n",
    "source_cl = 'worst-case (1)' # 'mean', 'worst-case (1)', worst-case (2)'Any\n",
    "\n",
    "if source_cl == 'mean':\n",
    "    # mean inlet source concentrations\n",
    "    source_0_pat = np.tile(np.random.normal(0.65, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "    source_1_pat = np.tile(np.random.normal(0.75, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "\n",
    "elif source_cl == 'worst-case (1)':\n",
    "    # worst-case inlet source concentrations (case 1)\n",
    "    source_0_pat = np.tile(np.random.normal(0.4, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "    source_1_pat = np.tile(np.random.normal(0.95, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "\n",
    "elif source_cl == 'worst-case (2)':\n",
    "    # worst-case inlet source concentrations (case 2)\n",
    "    source_0_pat = np.tile(np.random.normal(0.9, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "    source_1_pat = np.tile(np.random.normal(0.55, 0.15, wdn.net_info['nt']), sim_days_qual)\n",
    "\n",
    "wn.add_pattern(\"source_0_pat\", source_0_pat)\n",
    "wn.add_source(\"source_0\", source_0, \"CONCEN\", 1, \"source_0_pat\")\n",
    "wn.add_pattern(\"source_1_pat\", source_1_pat)\n",
    "wn.add_source(\"source_1\", source_1, \"CONCEN\", 1, \"source_1_pat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fa52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24-hour simulation period with 15-minute time steps\n",
    "nt = 24\n",
    "wn.options.time.duration = (nt * sim_days_qual * 3600) - (0.25 * 3600)\n",
    "wn.options.time.hydraulic_timestep = 60 * 15\n",
    "wn.options.time.quality_timestep = 60 * 5\n",
    "wn.options.time.report_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.options.time.pattern_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.options.time.rule_timestep = wn.options.time.hydraulic_timestep\n",
    "wn.convert_controls_to_rules(priority=3) \n",
    "\n",
    "# setup water quality parameters\n",
    "wn.options.quality.parameter = \"CHEMICAL\"\n",
    "wn.options.reaction.bulk_coeff = (-0.5/3600/24) # units = 1/second\n",
    "wall_coeff = get_wall_coeff(wdn)\n",
    "idx = 0\n",
    "for name, link in wn.links():\n",
    "    if isinstance(link, wntr.network.Pipe):\n",
    "        link.wall_coeff = wall_coeff[idx]\n",
    "    idx += 1\n",
    "\n",
    "# run water quality solver\n",
    "sim = wntr.sim.EpanetSimulator(wn)\n",
    "results = sim.run_sim()\n",
    "df_qual = pd.DataFrame()\n",
    "\n",
    "# obtain quality (disinfectant) results\n",
    "df_qual['timestamp'] = results.node['quality'].index.values / 3600\n",
    "for col in results.node['quality'].columns:\n",
    "    df_qual[col] = results.node['quality'][col].values\n",
    "df_qual.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4244366",
   "metadata": {},
   "source": [
    "Plot disinfectant source patterns at DMA inlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98965883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting code\n",
    "plt.figure()\n",
    "df_qual[source_0].plot(label=sources[0], color='tab:blue')\n",
    "df_qual[source_1].plot(label=sources[1], color='tab:red')\n",
    "plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "plt.ylabel('Inlet residual [mg/L]', fontsize=12)\n",
    "if sim_days_qual <= 1:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 6))\n",
    "elif sim_days_qual > 1 and sim_days_qual < 5:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 12))\n",
    "else:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 24))\n",
    "plt.legend(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2ef9e",
   "metadata": {},
   "source": [
    "Plot disinfectant residuals across the network at time step $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c31cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_t = 38\n",
    "t = 6*96 + last_t\n",
    "legend_labels = {'Inlet': 'black', 'Sensor': 'black'}\n",
    "plot_network_states(wdn, plot_type='disinfectant', sensor_nodes=sensor_names, vals_df=df_qual.T, t=t, legend_labels=legend_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c7139",
   "metadata": {},
   "source": [
    "Plot disinfectant time series at select model nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef97264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting data\n",
    "node_to_plot = 'node_0187' # existing control\n",
    "# node_to_plot = 'node_1900' # existing control\n",
    "# node_to_plot = 'node_0189' # existing control\n",
    "node_to_plot = 'node_1149' # existing control\n",
    "# node_to_plot = 'node_2397' # self-cleaning control\n",
    "node_to_plot = 'node_2506'\n",
    "\n",
    "# plotting code\n",
    "plt.figure()\n",
    "df_qual[node_to_plot].plot(label=node_to_plot, color='tab:blue')\n",
    "plt.xlabel('Simulation time [h]', fontsize=12)\n",
    "plt.ylabel('Disinfectant residual [mg/L]', fontsize=12)\n",
    "if sim_days_qual <= 1:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 6))\n",
    "elif sim_days_qual > 1 and sim_days_qual < 5:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 12))\n",
    "else:\n",
    "    plt.xticks(np.arange(0, nt * sim_days_qual + 1, 24))\n",
    "plt.legend(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c4948",
   "metadata": {},
   "source": [
    "We compute the **standard deviation** (SD) of disinfectant residuals at each node across the last 24-h period of the 7-day simulation. Similar to the flow variability metrics, this aims to highlight nodes with greater disinfectant variability for different control configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = pd.DataFrame(df_qual.tail(wdn.net_info['nt']*(sim_days_qual-1)).std(), columns=['qual_std'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.75, 7.25))\n",
    "ax.margins(0.025, 0.025)\n",
    "\n",
    "node_weight_name = 'qual_std'\n",
    "\n",
    "cbar_title = 'Standard deviation [mg/L]'\n",
    "colorbar_ticks = (np.arange(0, 0.31, 0.1), [str(round(x, 2)) for x in np.arange(0, 0.21, 0.1)] + [r\"$\\geq 0.3$\"])\n",
    "clims = (0, 0.3)\n",
    "\n",
    "cmap = cm.get_cmap('RdYlBu').reversed()\n",
    "\n",
    "# draw network and plot node weights\n",
    "uG = nx.from_pandas_edgelist(wdn.link_df, source='node_out', target='node_in')\n",
    "pos = {row['node_ID']: (row['xcoord'], row['ycoord']) for _, row in wdn.node_df.iterrows()}\n",
    "\n",
    "norm = plt.Normalize(vmin=clims[0], vmax=clims[1])\n",
    "node_colors = cmap(norm(metric[node_weight_name]))\n",
    "nx.draw(uG, pos, nodelist=metric.index, node_size=30, node_shape='o', alpha=0.75, linewidths=0, node_color=node_colors, cmap=cmap, edge_color='grey', ax=ax)\n",
    "\n",
    "# create a color bar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array(metric[node_weight_name])\n",
    "colorbar = plt.colorbar(sm, orientation='horizontal', pad=-0.025, shrink=0.8)\n",
    "colorbar.set_label(cbar_title, fontsize=12)\n",
    "colorbar.set_ticks(colorbar_ticks[0])\n",
    "colorbar.set_ticklabels(colorbar_ticks[1], fontsize=11)\n",
    "\n",
    "nx.draw_networkx_nodes(uG, pos, nodelist=wdn.net_info['reservoir_names'], node_size=120, node_shape='s', node_color='black', edgecolors='white') # draw reservoir nodes\n",
    "nx.draw_networkx_nodes(uG, pos, nodelist=sensor_names, node_size=75, node_shape='o', node_color='black', edgecolors='white') # draw sensor nodes\n",
    "\n",
    "sensor_labels = {node: str(idx+1) for (idx, node) in enumerate(sensor_names)}\n",
    "labels_sen = nx.draw_networkx_labels(uG, pos, sensor_labels, font_size=12, verticalalignment='bottom')\n",
    "for _, label in labels_sen.items():\n",
    "    label.set_y(label.get_position()[1] + 70)\n",
    "\n",
    "legend_labels = {'Inlet': 'black', 'Sensor': 'black'}\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o' if label == 'Sensor' else 's' if label == 'Inlet' else None, markeredgewidth=2, markeredgecolor='white', color='white', markerfacecolor=color, markersize=10 if label == 'Sensor' else 11 if label == 'Inlet' else None, label=label) for label, color in legend_labels.items()]\n",
    "leg = plt.legend(handles=legend_handles, loc='upper right', frameon=True, borderpad=0.75)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414ca67",
   "metadata": {},
   "source": [
    "### Validation of AZP control configuration modelling through water quality sensor data\n",
    "We have approximately 3.5 months of continuous (15-minute) water quality data at the highlighted sensor nodes. This data corresponds to the (existing) AZP control configuration. In this section, we aim to validate the increase in disinfectant variability at sensor nodes within the areas of the network with greater hydraulic dynamics. We show this by performing a statistical analysis of sensor time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8276c9f",
   "metadata": {},
   "source": [
    "#### Disinfectant variability of raw time series\n",
    "The standard deviation is computed for each sensor node over the entire monitoring period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d88178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sensor data\n",
    "wq_data = pd.read_csv(os.path.join(data_path, 'wq_data.csv'))\n",
    "\n",
    "# delete missing data\n",
    "wq_data.dropna(how='any', inplace=True)\n",
    "\n",
    "# plot sensor data\n",
    "sensor_names = ['node_2746', 'node_1811', 'node_2367', 'node_2747', 'node_1809', 'node_2673', 'node_2506', 'node_1773', 'node_1802']\n",
    "sensor = 4\n",
    "\n",
    "plt.figure()\n",
    "wq_data[sensor_names[sensor-1]].plot(label=f'Sensor {sensor}', color='tab:blue')\n",
    "plt.xlabel('Time step', fontsize=12)\n",
    "plt.ylabel('Chlorine [mg/L]', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dbe58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute standard deviation (SD) and coefficient of variation (CV)\n",
    "sd = pd.DataFrame(wq_data.std(), columns=['sd'])\n",
    "cv = pd.DataFrame((wq_data.std() / wq_data.mean()), columns=['cv'])\n",
    "wq_metrics = sd.merge(cv, left_index=True, right_index=True)\n",
    "\n",
    "# plot variability metric spatially on sensor node map\n",
    "legend_labels = {'Sensor node': 'black'}\n",
    "plot_sensor_data(wdn, sensor_names, wq_metrics[['sd']], legend_labels=legend_labels, sensor_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f217a58",
   "metadata": {},
   "source": [
    "#### Disinfectant variability of differenced (stationary) time series\n",
    "Remove trend by differencing the time series. This is a common approach for making time series data stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72187eef",
   "metadata": {},
   "source": [
    "First, we demonstrate the differencing process on time series data of a selected sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sensor time series data\n",
    "idx = 4\n",
    "indices = wq_data.index.to_numpy()\n",
    "sensor_data = wq_data[sensor_names[idx-1]].to_numpy()\n",
    "\n",
    "# plot initial time series\n",
    "plt.figure(figsize=(5, 3.75))\n",
    "plt.plot(np.arange(0, len(sensor_data)), sensor_data, color='tab:blue', label=f'Sensor {idx}')\n",
    "plt.xlabel('15-minute time step', fontsize=12)\n",
    "plt.ylabel('Original data [mg/L]', fontsize=12)\n",
    "plt.tick_params(axis='x', labelsize=11)\n",
    "plt.tick_params(axis='y', labelsize=11)\n",
    "leg = plt.legend(loc='upper right', frameon=True, borderpad=0.5, fontsize=11)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(0.5)\n",
    "plt.ylim(0, 1.5)\n",
    "plt.show()\n",
    "\n",
    "# compute mean and sd of time series data\n",
    "mean = np.mean(sensor_data)\n",
    "print(f'Mean: {mean} mg/L')\n",
    "sd = np.std(sensor_data)\n",
    "print(f'Standard deviation (SD): {sd} mg/L')\n",
    "\n",
    "# check if time series is stationary\n",
    "result = adfuller(sensor_data)\n",
    "print(f'ADF statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print('Critical values:')\n",
    "for key, value in result[4].items():\n",
    " print(f'{key}: {value}')\n",
    "\n",
    "# differenced time series\n",
    "sensor_data_diff = np.diff(sensor_data, n=1)\n",
    "\n",
    "# delete indices with time step gap\n",
    "indices_diff = np.diff(indices, n=1)\n",
    "delete = np.where(indices_diff > 1)\n",
    "sensor_data_diff = np.delete(sensor_data_diff, delete)\n",
    "\n",
    "plt.figure(figsize=(5, 3.75))\n",
    "plt.plot(np.arange(0, len(sensor_data_diff)), sensor_data_diff, color='tab:red', label=f'Sensor {idx}')\n",
    "plt.xlabel('15-minute time step', fontsize=12)\n",
    "plt.ylabel('Differenced data [mg/L]', fontsize=12)\n",
    "plt.tick_params(axis='x', labelsize=11)\n",
    "plt.tick_params(axis='y', labelsize=11)\n",
    "leg = plt.legend(loc='upper right', frameon=True, borderpad=0.5, fontsize=11)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(0.5)\n",
    "plt.ylim(-0.5, 0.5)\n",
    "plt.show()\n",
    "\n",
    "result = adfuller(sensor_data_diff)\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'usedlag: {result[2]}')\n",
    "\n",
    "# compute mean of differenced time series data\n",
    "mean = np.mean(sensor_data_diff)\n",
    "print(f'Mean: {mean} mg/L')\n",
    "\n",
    "# compute SD of differenced time series data\n",
    "sd = np.std(sensor_data_diff)\n",
    "print(f'Standard deviation (SD): {sd} mg/L')\n",
    "\n",
    "# compute MAD of differenced time series data\n",
    "mad = np.mean(np.abs(sensor_data_diff))\n",
    "print(f'Mean absolute deviation (MAD): {mad} mg/L')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9309a",
   "metadata": {},
   "source": [
    "Here, we compute the standard deviation (SD) and mean absolute deviation (MAD) values for each differenced time series data. These values are included in the previously defined `wq_metrics` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603bdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq_metrics[['sd_data', 'mad_data']] = None\n",
    "sensor_diff_df = pd.DataFrame()\n",
    "\n",
    "for idx, name in enumerate(sensor_names):\n",
    "    \n",
    "    # get time series\n",
    "    sensor_data = wq_data[name].to_numpy()\n",
    "    indices = wq_data.index.to_numpy()\n",
    "    \n",
    "    # compute differenced time series\n",
    "    sensor_data_diff = np.diff(sensor_data, n=1)\n",
    "    indices_diff = np.diff(indices, n=1)\n",
    "    delete = np.where(indices_diff > 1)\n",
    "    sensor_data_diff = np.delete(sensor_data_diff, delete)\n",
    "\n",
    "    # save differenced sensor data to dataframe\n",
    "    sensor_diff_df[idx+1] = sensor_data_diff\n",
    "    \n",
    "    # compute rmse of differenced time series\n",
    "    sd = np.sqrt(np.mean(sensor_data_diff ** 2))\n",
    "    wq_metrics['sd_data'][name] = sd\n",
    "    \n",
    "    # compute mae of differenced time series\n",
    "    mad = np.mean(np.abs(sensor_data_diff))\n",
    "    wq_metrics['mad_data'][name] = mad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3218e53",
   "metadata": {},
   "source": [
    "Results plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ffd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD and MAD metrics bar plot\n",
    "ax = wq_metrics[['sd_data', 'mad_data']].plot(kind='bar', figsize=(7.4, 4.05), color=['tab:purple', 'tab:green'], legend=True, fontsize=12, alpha=1)\n",
    "ax.set_xlabel(\"Sensor ID\", fontsize=12)\n",
    "ax.set_ylabel(\"Metric value [mg/L]\", fontsize=12)\n",
    "ax.tick_params(axis='x', labelsize=11)\n",
    "ax.tick_params(axis='y', labelsize=11)\n",
    "ax.set_xticklabels(np.arange(1, 10))\n",
    "plt.yticks(np.arange(0, 0.03, 0.005))\n",
    "plt.xticks(rotation=0)\n",
    "leg = plt.legend(labels=['SD', 'MAD'], loc='upper right', frameon=False, borderpad=0.75)\n",
    "leg.get_frame().set_edgecolor('black')\n",
    "leg.get_frame().set_linewidth(0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_df = pd.DataFrame()\n",
    "custom_bins = np.linspace(-0.4, 0.4, 9)\n",
    "\n",
    "# iterate through each column in the original dataframe and compute frequency as percentage\n",
    "for col_idx in range(sensor_diff_df.shape[1]):\n",
    "\n",
    "    percentages = pd.cut(sensor_diff_df.iloc[:, col_idx], bins=custom_bins).value_counts() / len(sensor_diff_df) * 100\n",
    "    percentages = percentages.sort_index(ascending=False)\n",
    "    percentages = percentages.apply(lambda x: np.nan if np.abs(x) <= 0.01 else x)  # replace 0 values with np.nan\n",
    "    \n",
    "    # append the percentages to historgram_df\n",
    "    histogram_df[col_idx] = percentages\n",
    "\n",
    "# make custom colorbar\n",
    "min_val, max_val = 0,1.0\n",
    "n = 10\n",
    "orig_cmap = cm.Blues\n",
    "colors = orig_cmap(np.linspace(min_val, max_val, n))\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"mycmap\", colors)\n",
    "\n",
    "norm = plt.Normalize(vmin=0, vmax=100)\n",
    "    \n",
    "# plot column heatmap\n",
    "plt.figure(figsize=(8, 4))\n",
    "heatmap = sns.heatmap(histogram_df, annot=True, cmap=cmap, fmt=\".1f\", cbar_kws={'label': 'Frequency [%]', 'norm': norm}, linewidths=1, linecolor='white', annot_kws={\"fontsize\":11})\n",
    "heatmap.tick_params(axis='x', labelsize=11)\n",
    "heatmap.tick_params(axis='y', labelsize=11)\n",
    "heatmap.set_xticklabels(np.arange(1, 10))\n",
    "heatmap.collections[0].set_clim(0, 100)\n",
    "plt.xlabel('Sensor ID', fontsize=12)\n",
    "plt.ylabel('Differenced data bins [mg/L]', fontsize=12)\n",
    "\n",
    "# modify colorbar\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.set_label('Frequency [%]', fontsize=12)\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "cbar.set_ticks([0, 20, 40, 60, 80, 100])\n",
    "cbar.outline.set_edgecolor('black') \n",
    "cbar.outline.set_linewidth(1)\n",
    "\n",
    "\n",
    "for _, spine in heatmap.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4946a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variability metric spatially on sensor node map\n",
    "legend_labels = {'Sensor node': 'black'}\n",
    "plot_sensor_data(wdn, sensor_names, wq_metrics[['mad_data']], legend_labels=legend_labels, sensor_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1715b22",
   "metadata": {},
   "source": [
    "#### Granger causality (NOT INCLUDED IN PAPER)\n",
    "In addition to each individual sensor's time series, we also investigate the connectivity between two sensors through the Granger causality test.\n",
    "\n",
    "First, we demonstrate the granger causality test results for a selected pair of sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c371a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select sensor indices\n",
    "idx1 = 2\n",
    "idx2 = 5\n",
    "\n",
    "# define sensor data\n",
    "sensor1_data = wq_data[sensor_names[idx1-1]].to_numpy()\n",
    "sensor2_data = wq_data[sensor_names[idx2-1]].to_numpy()\n",
    "\n",
    "# difference sensor data to ensure stationarity\n",
    "sensor1_diff = np.diff(sensor1_data, n=1).reshape(-1, 1)\n",
    "sensor2_diff = np.diff(sensor2_data, n=1).reshape(-1, 1)\n",
    "\n",
    "# define max lag\n",
    "n_lag = 96\n",
    "\n",
    "# run granger causality test\n",
    "data = np.hstack((sensor2_diff, sensor1_diff))\n",
    "results = grangercausalitytests(data, n_lag, verbose=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e340a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract F-statistics for each lag\n",
    "f_statistics = []\n",
    "for lag in range(1, n_lag + 1):\n",
    "    f_statistic = results[lag][0]['ssr_ftest'][0]\n",
    "    f_statistics.append(f_statistic)\n",
    "    \n",
    "# ploy F-statistics\n",
    "plt.plot(np.arange(0, len(f_statistics)), f_statistics, color='tab:blue')\n",
    "plt.xlabel('Lag', fontsize=12)\n",
    "plt.ylabel('F-statistic', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f12e7",
   "metadata": {},
   "source": [
    "Here, we loop through all sensor pairs to compute all granger causality results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe314ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensor_names = ['node_2746', 'node_1811', 'node_2367', 'node_2747', 'node_1809', 'node_2673', 'node_2506', 'node_1773', 'node_1802'] # edit accordingly\n",
    "# # sensor_names = ['node_2746', 'node_1811', 'node_2367', 'node_2747', 'node_1809', 'node_2673', 'node_1773', 'node_1802']\n",
    "\n",
    "# # create an empty DataFrame to store results\n",
    "# granger_df = pd.DataFrame(columns=['sensor_from', 'sensor_to', 'f_statistic', 'lag'])\n",
    "\n",
    "# n_lag = 96\n",
    "# idx = 0\n",
    "    \n",
    "# # iterate through each combination of two sensors\n",
    "# for sensor_from, sensor_to in combinations(sensor_names, 2):\n",
    "#     for order in [(sensor_from, sensor_to), (sensor_to, sensor_from)]:\n",
    "    \n",
    "#         # extract sensor data\n",
    "#         data_from = wq_data[order[0]].to_numpy()\n",
    "#         data_to = wq_data[order[1]].to_numpy()\n",
    "\n",
    "#         # difference sensor data to ensure stationarity\n",
    "#         data_from_diff = np.diff(data_from, n=1).reshape(-1, 1)\n",
    "#         data_to_diff = np.diff(data_to, n=1).reshape(-1, 1)\n",
    "\n",
    "#         # combine the two arrays\n",
    "#         data = np.hstack((data_to_diff, data_from_diff))\n",
    "\n",
    "#         # perform Granger causality test\n",
    "#         results = grangercausalitytests(data, n_lag, verbose=False)\n",
    "\n",
    "#         # find the lag with the maximum F-statistic\n",
    "#         max_lag = np.argmax([results[lag][0]['ssr_ftest'][0] for lag in range(1, n_lag + 1)]) + 1\n",
    "#         max_f_statistic = results[max_lag][0]['ssr_ftest'][0]\n",
    "\n",
    "#         # append the results to the DataFrame\n",
    "#         granger_df.loc[idx, ['sensor_from', 'sensor_to', 'f_statistic', 'lag']] = [order[0], order[1], max_f_statistic, max_lag]\n",
    "\n",
    "#         idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d4907",
   "metadata": {},
   "source": [
    "Make grid plot to illustrate granger causality results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ea15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create pivot table for easy plotting\n",
    "# pivot_df = granger_df.pivot(index='sensor_from', columns='sensor_to', values='f_statistic')\n",
    "# pivot_df = pivot_df.reindex(index=sensor_names, columns=sensor_names)\n",
    "\n",
    "# # create heatmap}\n",
    "# # plt.figure(figsize=(10, 8))\n",
    "# # cmap='RdYlBu_r'\n",
    "# cmap = 'Blues'\n",
    "# vmin, vmax = 0, 500\n",
    "# cax = plt.imshow(pivot_df.astype(float), cmap=cmap, interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "# plt.xticks(np.arange(9), np.arange(1, 10))\n",
    "# plt.yticks(np.arange(9), np.arange(1, 10))\n",
    "# cbar = plt.colorbar(cax, label='F-statistic')\n",
    "# cbar.set_label('F-statistic', fontsize=12)\n",
    "# plt.xlabel('Sensor To', fontsize=12)\n",
    "# plt.ylabel('Sensor From', fontsize=12)\n",
    "# plt.tick_params(axis='x', which='both', bottom=False, top=True, labeltop=True, labelbottom=False)\n",
    "# plt.gca().xaxis.set_label_position('top') \n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
